import re
import math
from typing import List, Tuple, Dict
import numpy as np
import torch
from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report

# --- ä½ çµ¦çš„åˆ‡æ®µå‡½å¼ï¼ˆæˆ‘ç¨å¾®ä¿®æ­£äº†ä¸€äº›ç´°ç¯€ï¼‰ ---
def split_content(text: str, min_seg_len: int = 100) -> List[str]:
    """
    ä¾æ“šç©ºæ ¼åŠä¸­æ–‡æ¨™é»ç¬¦è™Ÿå°‡æ–‡æœ¬åˆ‡åˆ†æˆç‰‡æ®µï¼Œ
    å†ç´¯ç©ç‰‡æ®µç›´åˆ°ç´¯ç©é•·åº¦é”åˆ° min_seg_lenï¼Œä½œç‚ºä¸€å€‹åˆ†æ®µè¼¸å‡ºã€‚
    - min_seg_len ä»¥å­—å…ƒæ•¸è¨ˆï¼ˆä¸­æ–‡ä¸€å­—ä¸€ç¢¼ï¼‰
    """
    if not isinstance(text, str) or text.strip() == "":
        return []
    # ç§»é™¤è‹±æ–‡å­—æ¯ï¼ˆå¦‚ä½ åŸæœ¬çš„éœ€æ±‚ï¼‰
    text = re.sub(r'[A-Za-z]', '', text)
    # åˆ‡åˆ†æ¨™é»ï¼ˆä¿ç•™åˆ†éš”ç¬¦ï¼‰
    pattern = r'([ã€‚ï¼ï¼Ÿï¼›ï¼Œã€,.\s])'
    parts = re.split(pattern, text)
    # åˆä½µåˆ†éš”ç¬¦å›å‰ä¸€ç‰‡æ®µ
    fragments = []
    current_frag = ""
    for part in parts:
        if part == "":
            continue
        if re.match(pattern, part):
            current_frag += part
            if current_frag.strip():
                fragments.append(current_frag.strip())
            current_frag = ""
        else:
            current_frag += part
    if current_frag.strip():
        fragments.append(current_frag.strip())

    # ç´¯ç© fragments ç›´åˆ°é•·åº¦é”åˆ° min_seg_len
    segments = []
    current_segment = ""
    for frag in fragments:
        candidate = (current_segment + " " + frag).strip() if current_segment else frag
        if len(candidate) < min_seg_len:
            current_segment = candidate
        else:
            segments.append(candidate.strip())
            current_segment = ""
    # è‹¥æœ€å¾Œ remainder ä¸ç‚ºç©ºï¼Œä¹Ÿç•¶ä½œä¸€å€‹ segmentï¼ˆé¿å…éºæ¼ï¼‰
    if current_segment.strip():
        segments.append(current_segment.strip())
    return segments

# --- æ‰¹æ¬¡åŒ– segment é€²è¡Œæ¨è«–ï¼ˆä½¿ç”¨ä½ çš„ model èˆ‡ tokenizerï¼‰ ---
@torch.no_grad()
def predict_segments(model, tokenizer, segments: List[str], device: str, batch_size: int = 64, max_length: int = 512) -> np.ndarray:
    """
    å›å‚³æ¯å€‹ segment çš„æ­£é¡æ©Ÿç‡ï¼ˆshape = (len(segments),)ï¼‰
    """
    model.eval()
    probs = []
    # simple batching
    for i in range(0, len(segments), batch_size):
        batch_texts = segments[i:i+batch_size]
        enc = tokenizer(batch_texts, padding=True, truncation=True, max_length=max_length, return_tensors="pt")
        enc = {k: v.to(device) for k,v in enc.items()}
        out = model(input_ids=enc["input_ids"], attention_mask=enc["attention_mask"])
        

        # å…¼å®¹ä¸‰ç¨®è¿”å›æ ¼å¼
        if isinstance(out, dict):
            # ContrastiveClassifier è¿”å›å­—å…¸ {"logits": ..., "features": ...}
            logits = out["logits"]
        elif isinstance(out, tuple):
            # EncoderHead (MSL.py) è¿”å› tuple (logits, z)
            logits = out[0]
        else:
            # BCEClassifier ç›´æ¥è¿”å›å¼µé‡
            logits = out

        # logits = out["logits"]

        # For binary classification, get probability of positive class (index 1)
        # p = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()
        
        # ğŸ” æ ¹æ“š logits ç¶­åº¦è‡ªå‹•åˆ¤æ–·åˆ†é¡é¡å‹
        if logits.dim() == 1 or logits.shape[-1] == 1:
            # äºŒåˆ†é¡ BCE æ ¼å¼: (batch_size,) æˆ– (batch_size, 1)
            if logits.dim() == 2:
                logits = logits.squeeze(-1)
            p = torch.sigmoid(logits).detach().cpu().numpy()
        else:
            # å¤šåˆ†é¡ CE æ ¼å¼: (batch_size, num_classes)
            p = torch.softmax(logits, dim=1)[:, 1].detach().cpu().numpy()

        probs.append(p)
    if len(probs) == 0:
        return np.array([])
    return np.concatenate(probs, axis=0)

# --- å¾ segments çš„æ©Ÿç‡èšåˆåˆ° post-level ---
def aggregate_post_from_segment_probs(seg_probs: np.ndarray, threshold: float = 0.5, agg_mode: str = "any") -> int:
    """
    agg_mode:
      - "any": è‹¥ä»»ä¸€ segment prob >= threshold -> post positive
      - "max": ä½¿ç”¨ max(seg_probs) >= thresholdï¼ˆç­‰åŒ anyï¼‰
      - "topk": è‹¥ top-k ä¸­æœ‰ >= thresholdï¼ˆå¯æ“´å……ï¼‰
    å›å‚³ 1 (positive) æˆ– 0 (negative)
    """
    if seg_probs.size == 0:
        return 0
    if agg_mode in ("any", "max"):
        return int(np.max(seg_probs) >= threshold)
    # å¯æ“´å……å…¶ä»–èšåˆç­–ç•¥
    raise ValueError("Unknown agg_mode")

# --- é‡å° test dataframe çš„ batch processingï¼ˆæ¯ç¯‡è²¼æ–‡ï¼‰ ---
def evaluate_posts(model, tokenizer, df_test, text_col="segment", label_col="label",
                   min_seg_len: int = 18, threshold: float = 0.5,
                   device: str = "cuda", seg_batch_size: int = 64, max_length: int = 512,
                   verbose: bool = False) -> Dict:
    """
    df_test: DataFrame with one row per post, columns: text_col (full post), optional label_col (0/1)
    å›å‚³ dict åŒ…å« per-post predictions èˆ‡è©•ä¼°æŒ‡æ¨™ï¼ˆè‹¥æœ‰ labelï¼‰
    """
    posts = df_test[text_col].astype(str).tolist()
    golds = df_test[label_col].tolist() if (label_col in df_test.columns) else None

    all_post_preds = []
    all_post_probs = []  # store the max segment prob per post (for analysis)
    for idx, post in enumerate(posts):
        segments = split_content(post, min_seg_len=min_seg_len)
        if len(segments) == 0:
            # empty post -> predict negative
            all_post_preds.append(0)
            all_post_probs.append(0.0)
            continue
        seg_probs = predict_segments(model, tokenizer, segments, device=device,
                                     batch_size=seg_batch_size, max_length=max_length)
        post_pred = aggregate_post_from_segment_probs(seg_probs, threshold=threshold, agg_mode="any")
        all_post_preds.append(post_pred)
        all_post_probs.append(float(np.max(seg_probs) if seg_probs.size>0 else 0.0))

        if verbose and (idx % 100 == 0):
            print(f"Processed {idx}/{len(posts)} posts; segments={len(segments)}; top_prob={all_post_probs[-1]:.4f}")

    results = {"preds": all_post_preds, "probs": all_post_probs}

    if golds is not None:
        y_true = np.array(golds, dtype=int)
        y_pred = np.array(all_post_preds, dtype=int)
        acc = accuracy_score(y_true, y_pred)
        p, r, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=[0,1], average=None)
        macro = precision_recall_fscore_support(y_true, y_pred, average="macro")
        rpt = classification_report(y_true, y_pred, digits=4)
        results.update({
            "accuracy": acc,
            "precision_per_class": p.tolist(),
            "recall_per_class": r.tolist(),
            "f1_per_class": f1.tolist(),
            "macro": macro,
            "report": rpt
        })
    return results
